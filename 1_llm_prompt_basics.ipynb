{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "![i2b2 Logo](./images/transmart-logo.png)\n",
    "\n",
    "\n",
    "# Using LLM for Clinical Note Analysis (Zero-shot)\n",
    "This Notebook demonstrates how to use Azure-hosted OpenAI models with LangChain. The notebook follows a step-by-step approach to set up authentication, initialize the model, create structured prompts, and generate responses. The key components covered include:#\n",
    "\n",
    "- ## REVIEW !!!\n",
    "- Loading environment variables\n",
    "- Loading llm model\n",
    "- Creating and formatting chat prompts\n",
    "- Invoking the LLM model\n",
    "- Displaying the AI-generated response\n",
    "\n",
    "Each cell in the notebook builds upon the previous one to progressively set up and execute an AI-driven conversation."
   ],
   "id": "bf2bc9b0fb813186"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# -----------------------------------------------------------\n",
    "# 1. Load the Ollama Model\n",
    "# -----------------------------------------------------------\n",
    "# This cell loads a local Large Language Model (LLM) using LangChain's\n",
    "# `ChatOllama` wrapper. Make sure the model has been pulled via Ollama CLI before use.\n",
    "\n",
    "# To explore available models, visit:\n",
    "# - Ollama Library: https://ollama.com/library\n",
    "# - Hugging Face (for embeddings and additional models): https://huggingface.co/models\n",
    "\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# Define the model name — make sure this model is already downloaded using:\n",
    "#   ollama pull deepseek-v2:16b\n",
    "model_name = \"qwen2\"  # Alternatives: \"qwen2\", \"llama3\", etc.\n",
    "\n",
    "# Initialize the model with LangChain\n",
    "model = ChatOllama(model=model_name)\n",
    "\n",
    "print(f\"✅ Model '{model_name}' is loaded and ready to use.\")\n"
   ],
   "id": "82e6a97150f1d06f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Basic Prompt Interaction - Simple Query\n",
    "\n",
    "<img src=\"./images/basic_prompt.png\" alt=\"i2b2 Logo\" width=\"900\">\n",
    "\n"
   ],
   "id": "98d1e0333b2bd856"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# -----------------------------------------------------------\n",
    "# 2. Run a Simple Clinical Query with System + User Prompts\n",
    "# -----------------------------------------------------------\n",
    "# This tests the model by asking a simple clinical question using structured messages.\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=(\n",
    "        \"You are a knowledgeable medical provider. \"\n",
    "        \"Provide clear, evidence-based explanations about a medical conditions.\"\n",
    "    )),\n",
    "    HumanMessage(content=\"What is asthma? What are its common symptoms and treatments?\")\n",
    "]\n",
    "\n",
    "# Run inference\n",
    "response = model.invoke(messages)\n",
    "\n",
    "# Display result\n",
    "display(Markdown(\"### Model Response:\"))\n",
    "display(Markdown(response.content))\n"
   ],
   "id": "e019e06b683e2ea1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. Using ChatPromptTemplate for Dynamic Prompts\n",
    "\n",
    "This section shows how to create reusable prompt templates using LangChain’s `ChatPromptTemplate`.\n",
    "\n",
    "- **3.1**: Runs a dynamic medical query by filling in a condition (e.g., epilepsy) and a patient type (e.g., child).\n",
    "- **3.2**: Prepares a prompt template for clinical note extraction. This will be used later in Section 4 when we insert actual patient notes.\n",
    "\n",
    "Prompt templates make it easier to reuse the same structure with different inputs.\n",
    "\n",
    "<img src=\"./images/prompt_template.png\" alt=\"Prompt Template\" width=\"900\">\n"
   ],
   "id": "f02e27596486474"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# -----------------------------------------------------------\n",
    "# 3.1. Create a Reusable Prompt Template (Dynamic Querying)\n",
    "# -----------------------------------------------------------\n",
    "# This cell demonstrates how to build a dynamic prompt template using placeholders\n",
    "# for different medical conditions and patient profiles. The prompt is populated\n",
    "# with variables at runtime and sent to the LLM for inference.\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Define input variables\n",
    "patient_type = \"5 year-old\"\n",
    "disease = \"epilepsy\"\n",
    "\n",
    "# Define a role-based prompt using variable placeholders\n",
    "messages = [\n",
    "    (\"system\",\n",
    "     \"You are a knowledgeable medical provider. Provide clear, evidence-based explanations appropriate for a {patient_type} patient.\"),\n",
    "\n",
    "    (\"human\",\n",
    "     \"What is {disease}? What are its common symptoms and treatments?\")\n",
    "]\n",
    "\n",
    "# Create a prompt template with dynamic inputs\n",
    "prompt_template = ChatPromptTemplate.from_messages(messages)\n",
    "\n",
    "# Fill the template with actual values\n",
    "prompt = prompt_template.invoke({\n",
    "    \"patient_type\": patient_type,\n",
    "    \"disease\": disease\n",
    "})\n",
    "\n",
    "# Run the model with the constructed prompt\n",
    "response = model.invoke(prompt)\n",
    "\n",
    "# Display the generated answer\n",
    "display(Markdown(\"### AI Response\"))\n",
    "display(Markdown(response.content))\n"
   ],
   "id": "c87b037636a9b61f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# -----------------------------------------------------------\n",
    "# 3.2. Clinical Note Extraction Prompt\n",
    "# -----------------------------------------------------------\n",
    "# This cell defines a reusable prompt template to guide the LLM\n",
    "# in extracting structured clinical information from a free-text note.\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# Define the prompt structure using role-based messages\n",
    "messages_notes = [\n",
    "    (\"system\",\n",
    "     \"You are an advanced medical documentation assistant. \"\n",
    "     \"Your task is to extract key clinical details from unstructured notes in a clear and structured format.\"),\n",
    "\n",
    "    (\"human\",\n",
    "     \"Analyze the following clinical note:\\n\\n\"\n",
    "     \"{patient_note}\\n\\n\"\n",
    "     \"Extract the following:\\n\"\n",
    "     \"1. Patient demographics\\n\"\n",
    "     \"2. Chief complaints\\n\"\n",
    "     \"3. Current medications\\n\"\n",
    "     \"4. Does the patient have asthma? (Yes/No)\\n\\n\"\n",
    "     \"Format your response using clear, structured bullet points.\")\n",
    "]\n",
    "\n",
    "# Create the prompt template with a placeholder for the clinical note\n",
    "prompt_template_notes = ChatPromptTemplate.from_messages(messages_notes)\n"
   ],
   "id": "4c7c6ee3663290b4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4. Extract and Decode Notes from i2b2 Encounter Table\n",
    "\n",
    "In this section, we explore how to work with real clinical notes stored in a simulated i2b2 `visit_dimension` table. These notes are encoded in BinHex format and need to be decoded before being used in a prompt.\n",
    "\n",
    "### What You'll Do:\n",
    "- **4.1**: Load and inspect the structure of the CSV file containing patient visits and encoded notes.\n",
    "- **4.2**: Interactively select a patient and encounter to preview the decoded note.\n",
    "- **4.3**: Use the previously defined prompt template to extract structured clinical information from a real decoded note.\n",
    "\n",
    "This prepares the data for downstream tasks like summarization or diagnostic tagging using a large language model.\n"
   ],
   "id": "43cf5b1c680a28be"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# -----------------------------------------------------------\n",
    "# 4.1. Load and Explore Visit Data from i2b2-Mimicking CSV\n",
    "# -----------------------------------------------------------\n",
    "# This cell loads a simulated `visit_dimension` table similar to what is used in i2b2.\n",
    "# It includes clinical notes stored in BinHex format and related visit metadata.\n",
    "\n",
    "# Each record includes:\n",
    "# - encounter_num: Unique visit ID\n",
    "# - patient_num: Patient identifier\n",
    "# - start_date, end_date: Visit timestamps\n",
    "# - location_cd, location_path: Care setting info\n",
    "# - visit_blob: BinHex-encoded clinical note\n",
    "\n",
    "# Purpose:\n",
    "# Load the data into a pandas DataFrame and inspect the structure before decoding.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the visit-level dataset\n",
    "csv_path = \"datafiles/i2b2_encounter_table.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Preview the first 10 records\n",
    "df.head(10)\n"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# -----------------------------------------------------------\n",
    "# 4.2. Interactive Exploration and Decoding of Clinical Notes\n",
    "# -----------------------------------------------------------\n",
    "# This cell allows users to interactively select a patient and encounter\n",
    "# to preview the decoded clinical note (stored as BinHex in the dataset).\n",
    "\n",
    "import binascii\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Step 1: Create dropdown for unique patient IDs\n",
    "distinct_patients = sorted(df['patient_num'].unique())\n",
    "\n",
    "patient_dropdown = widgets.Dropdown(\n",
    "    options=distinct_patients,\n",
    "    description=\"Patient #:\",\n",
    "    layout=widgets.Layout(width='25%')\n",
    ")\n",
    "\n",
    "# Step 2: Encounter dropdown (updates based on patient selection)\n",
    "encounter_dropdown = widgets.Dropdown(\n",
    "    options=[],\n",
    "    description=\"Encounter #:\",\n",
    "    layout=widgets.Layout(width='25%')\n",
    ")\n",
    "\n",
    "# Step 3: Update encounters dynamically when patient is selected\n",
    "def update_encounters(*args):\n",
    "    patient_encounters = df[df['patient_num'] == patient_dropdown.value]['encounter_num'].tolist()\n",
    "    encounter_dropdown.options = patient_encounters\n",
    "\n",
    "# Step 4: Decode and display the selected clinical note\n",
    "def decode_and_preview(patient_num, encounter_num):\n",
    "    selected_row = df[\n",
    "        (df['patient_num'] == patient_num) &\n",
    "        (df['encounter_num'] == encounter_num)\n",
    "    ].iloc[0]\n",
    "\n",
    "    hex_blob = selected_row[\"visit_blob\"].replace(\"0x\", \"\")\n",
    "    decoded_note = binascii.unhexlify(hex_blob).decode(\"utf-8\", errors=\"ignore\")\n",
    "\n",
    "    display(Markdown(f\"### Clinical Note Preview (Patient {patient_num}, Encounter {encounter_num})\"))\n",
    "    display(Markdown(f\"```text\\n{decoded_note}\\n```\"))\n",
    "\n",
    "# Step 5: Set up dropdown linkage and render interface\n",
    "patient_dropdown.observe(update_encounters, names='value')\n",
    "update_encounters()\n",
    "\n",
    "widgets.interact(\n",
    "    decode_and_preview,\n",
    "    patient_num=patient_dropdown,\n",
    "    encounter_num=encounter_dropdown\n",
    ")\n"
   ],
   "id": "bf423cd2524760ce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# -----------------------------------------------------------\n",
    "# 4.3. Analyze a Real Patient Note Using the Prompt\n",
    "# -----------------------------------------------------------\n",
    "# This cell selects a decoded clinical note for a given patient and encounter,\n",
    "# fills the clinical extraction prompt (prepared in Cell 3.2), and runs it through the LLM.\n",
    "\n",
    "# Define patient and encounter to analyze\n",
    "patient_num = 1000000002\n",
    "encounter_num = 475326\n",
    "\n",
    "# Extract and decode the clinical note\n",
    "selected_row = df[\n",
    "    (df['patient_num'] == patient_num) &\n",
    "    (df['encounter_num'] == encounter_num)\n",
    "].iloc[0]\n",
    "\n",
    "hex_blob = selected_row[\"visit_blob\"].replace(\"0x\", \"\")\n",
    "decoded_note = binascii.unhexlify(hex_blob).decode(\"utf-8\", errors=\"ignore\")\n",
    "\n",
    "# Fill the template with the note text\n",
    "filled_prompt = prompt_template_notes.invoke({\"patient_note\": decoded_note})\n",
    "\n",
    "# Invoke the model with the prompt\n",
    "clinical_response = model.invoke(filled_prompt)\n",
    "\n",
    "# Display the structured output\n",
    "from IPython.display import display, Markdown\n",
    "display(Markdown(\"### Extracted Clinical Information\"))\n",
    "display(Markdown(clinical_response.content))\n"
   ],
   "id": "7710a63cdb61efe2",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
