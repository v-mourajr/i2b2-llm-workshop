{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0de48298",
   "metadata": {},
   "source": [
    "# ðŸ§  RAG Search Demo Without ChromaDB\n",
    "\n",
    "This notebook demonstrates how to perform semantic similarity search over clinical notes **without using ChromaDB**, using a CSV file with precomputed embeddings and documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2083838e",
   "metadata": {},
   "source": [
    "## Step 1: Load consolidated CSV and decode vectors\n",
    "We decode the hex-encoded embeddings back into vectors and load document metadata."
   ]
  },
  {
   "cell_type": "code",
   "id": "cdd4a287",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T22:48:56.326228Z",
     "start_time": "2025-04-29T22:48:55.731106Z"
    }
   },
   "source": [
    "import csv\n",
    "import struct\n",
    "import binascii\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def load_consolidated_vectors(filepath):\n",
    "    documents = []\n",
    "    embeddings = []\n",
    "    metadata = []\n",
    "\n",
    "    with open(filepath, newline='', encoding=\"utf-8\") as csvfile:\n",
    "        # reader = csv.reader(csvfile)\n",
    "        reader = pd.read_csv(\"consolidated_table.csv\")\n",
    "\n",
    "        for row in reader:\n",
    "            patient_num, visit_date, doc_id, embed_id, hex_str, dtype, json_doc = row\n",
    "            hex_data = hex_str[2:] if hex_str.startswith(\"0x\") else hex_str\n",
    "            binary_data = binascii.unhexlify(hex_data)\n",
    "            vector = struct.unpack(f'{len(binary_data) // 4}f', binary_data)\n",
    "            embeddings.append(np.array(vector))\n",
    "            documents.append(json.loads(json_doc)[\"chroma:document\"])\n",
    "            metadata.append({\n",
    "                \"patient_num\": patient_num,\n",
    "                \"visit_date\": visit_date,\n",
    "                \"doc_id\": doc_id,\n",
    "                \"embedding_id\": embed_id\n",
    "            })\n",
    "    return documents, embeddings, metadata\n",
    "\n",
    "# Load your file here\n",
    "csv_path = \"./data_prep/patient_notes_hex/consolidated_table.csv\"\n",
    "documents, vectors, metadata = load_consolidated_vectors(csv_path)\n",
    "print(f\"Loaded {len(documents)} clinical notes with embeddings.\")"
   ],
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 7)",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 34\u001B[39m\n\u001B[32m     32\u001B[39m \u001B[38;5;66;03m# Load your file here\u001B[39;00m\n\u001B[32m     33\u001B[39m csv_path = \u001B[33m\"\u001B[39m\u001B[33m./data_prep/patient_notes_hex/consolidated_table.csv\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m---> \u001B[39m\u001B[32m34\u001B[39m documents, vectors, metadata = \u001B[43mload_consolidated_vectors\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcsv_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     35\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mLoaded \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(documents)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m clinical notes with embeddings.\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 18\u001B[39m, in \u001B[36mload_consolidated_vectors\u001B[39m\u001B[34m(filepath)\u001B[39m\n\u001B[32m     15\u001B[39m reader = pd.read_csv(\u001B[33m\"\u001B[39m\u001B[33mconsolidated_table.csv\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     17\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m row \u001B[38;5;129;01min\u001B[39;00m reader:\n\u001B[32m---> \u001B[39m\u001B[32m18\u001B[39m     patient_num, visit_date, doc_id, embed_id, hex_str, dtype, json_doc = row\n\u001B[32m     19\u001B[39m     hex_data = hex_str[\u001B[32m2\u001B[39m:] \u001B[38;5;28;01mif\u001B[39;00m hex_str.startswith(\u001B[33m\"\u001B[39m\u001B[33m0x\u001B[39m\u001B[33m\"\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m hex_str\n\u001B[32m     20\u001B[39m     binary_data = binascii.unhexlify(hex_data)\n",
      "\u001B[31mValueError\u001B[39m: too many values to unpack (expected 7)"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "934c90ba",
   "metadata": {},
   "source": [
    "## Step 2: Embed your query using AzureOpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165c3aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "embedding_model = AzureOpenAIEmbeddings(\n",
    "    model=os.getenv(\"AZURE_EMBEDDING_MODEL\"),\n",
    "    azure_deployment=os.getenv(\"AZURE_EMBEDDING_DEPLOYMENT\"),\n",
    "    api_version=os.getenv(\"AZURE_EMBEDDING_API_VERSION\"),\n",
    "    azure_endpoint=os.getenv(\"AZURE_EMBEDDING_ENDPOINT\"),\n",
    "    azure_ad_token_provider=None  # Replace with real token provider if needed\n",
    ")\n",
    "\n",
    "query = \"Who has asthma and is taking Fluticasone?\"\n",
    "query_vector = embedding_model.embed_query(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23744bd7",
   "metadata": {},
   "source": [
    "## Step 3: Perform cosine similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f520d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def search_similar(query_vector, all_vectors, top_k=10, score_threshold=0.45):\n",
    "    similarities = cosine_similarity([query_vector], all_vectors)[0]\n",
    "    top_indices = similarities.argsort()[::-1]\n",
    "    results = []\n",
    "    for idx in top_indices:\n",
    "        score = similarities[idx]\n",
    "        if score < score_threshold:\n",
    "            continue\n",
    "        results.append((idx, score))\n",
    "        if len(results) >= top_k:\n",
    "            break\n",
    "    return results\n",
    "\n",
    "results = search_similar(query_vector, vectors, top_k=10, score_threshold=0.45)\n",
    "print(f\"Top {len(results)} results above threshold:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1137e8",
   "metadata": {},
   "source": [
    "## Step 4: Display Retrieved Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b12ba2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for rank, (idx, score) in enumerate(results, 1):\n",
    "    print(f\"Document {rank}:\")\n",
    "    print(f\"  Relevance Score: {score:.6f}\")\n",
    "    print(f\"  Patient Num: {metadata[idx]['patient_num']}\")\n",
    "    print(f\"  Visit Date: {metadata[idx]['visit_date']}\")\n",
    "    print(f\"  Document ID: {metadata[idx]['doc_id']}\")\n",
    "    print(f\"  Excerpt: {documents[idx][:500]}...\")\n",
    "    print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e9f372",
   "metadata": {},
   "source": [
    "## (Optional) Step 5: Visualize Similarity Scores as Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8da5c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sim_matrix = cosine_similarity([query_vector], vectors)\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "sns.heatmap(sim_matrix, cmap=\"coolwarm\", xticklabels=False, yticklabels=False)\n",
    "plt.title(\"Query-to-All Vectors Cosine Similarity\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
