{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "![i2b2 Logo](images/transmart-logo.png)\n",
    "\n",
    "# Using ChromaDB + Embeddings to Search Patient Notes (RAG)\n",
    "\n",
    "This notebook demonstrates how to implement **Retrieval-Augmented Generation (RAG)** using **local text embeddings** and **ChromaDB** to search and analyze clinical notes stored in an i2b2-like format. The workflow includes decoding BinHex-encoded notes, embedding them using `MiniLM`, storing and retrieving them via ChromaDB, and using a local LLM (e.g., Qwen or LLaMA 3 via Ollama) to generate structured, clinically meaningful responses.\n",
    "\n",
    "### Key Concepts Covered\n",
    "\n",
    "- Decoding BinHex-encoded clinical notes from a simulated i2b2 table\n",
    "- Creating semantic vector embeddings with `MiniLM`\n",
    "- Storing notes and metadata in a persistent ChromaDB vector store\n",
    "- Performing similarity search and understanding cosine-based relevance scores\n",
    "- Filtering results to retain only the **most recent note per patient**\n",
    "- Using Maximal Marginal Relevance (MMR) to reduce redundancy in search results\n",
    "- Injecting retrieved context into a reusable prompt template\n",
    "- Generating structured, AI-powered responses using a local LLM via Ollama\n",
    "\n",
    "Each notebook cell builds on the previous one to demonstrate a complete RAG workflow tailored to **clinical informatics and patient note analysis**.\n",
    "\n",
    "> This notebook is part of the workshop: _Using LLMs to Search Patient Notes_.\n",
    "\n"
   ],
   "id": "e6022b84adefe37b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# -----------------------------------------------------------\n",
    "# 1. Load and Decode Clinical Notes from i2b2-Mimicking CSV\n",
    "# -----------------------------------------------------------\n",
    "# This cell loads visit-level data from a CSV file that mimics the i2b2 `visit_dimension` table\n",
    "# and decodes the BinHex-encoded clinical notes into readable text.\n",
    "#\n",
    "# Each record contains:\n",
    "#   - encounter_num: Unique encounter ID\n",
    "#   - patient_num: Patient identifier\n",
    "#   - start_date, end_date: Visit timestamps\n",
    "#   - location_cd, location_path: Clinic/service details\n",
    "#   - visit_blob: BinHex-encoded clinical note text\n",
    "\n",
    "import pandas as pd\n",
    "import binascii\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Define path to the input data file\n",
    "csv_path = \"datafiles/i2b2_encounter_table.csv\"\n",
    "\n",
    "# Load the CSV into a pandas DataFrame\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Define decoding function for BinHex notes\n",
    "def decode_note(hex_blob):\n",
    "    \"\"\"Decode a single BinHex-encoded string into plain text.\"\"\"\n",
    "    hex_str = hex_blob.replace(\"0x\", \"\")\n",
    "    return binascii.unhexlify(hex_str).decode(\"utf-8\", errors=\"ignore\")\n",
    "\n",
    "# Apply decoding to create a plain text column\n",
    "df[\"note_text\"] = df[\"visit_blob\"].apply(decode_note)\n",
    "\n",
    "# Display the first 10 decoded notes with key metadata\n",
    "display(df.head(10))\n"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Embed and Store Entire Clinical Notes in ChromaDB\n",
    "\n",
    "In this step, we process and store clinical notes as **entire documents** in a ChromaDB vector store. This preserves complete patient-level context for semantic search and retrieval.\n",
    "\n",
    "### Key Steps (2.1):\n",
    "1. **Embed Full Notes**:\n",
    "   - Each clinical note is transformed into a semantic vector using a transformer-based embedding model.\n",
    "2. **Store in ChromaDB**:\n",
    "   - The note and its metadata (patient ID, encounter number, date) are stored together in a persistent vector store.\n",
    "\n",
    "### Why Use This Approach?\n",
    "\n",
    "Storing full notes is valuable when:\n",
    "- You want to retrieve the entire clinical context (not just snippets or chunks)\n",
    "- The downstream task (e.g., summarization or decision support) benefits from broader information\n",
    "\n",
    "This method is most useful when each note is concise enough to fit within LLM input limits and clinical completeness is critical.\n",
    "\n",
    "<img src=\"./images/rag_full.png\" alt=\"RAG Full\" width=\"900\">\n"
   ],
   "id": "437c683321f7757e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# -----------------------------------------------------------\n",
    "# 2. Embed Clinical Notes Using Local MiniLM Embeddings and Store in ChromaDB\n",
    "# -----------------------------------------------------------\n",
    "# This cell embeds each clinical note using a Hugging Face transformer model\n",
    "# and stores the results in a ChromaDB vector store for later retrieval.\n",
    "#\n",
    "# The model used is `sentence-transformers/all-MiniLM-L6-v2`:\n",
    "# - Lightweight and optimized for local semantic search\n",
    "# - Produces 384-dimensional vectors suitable for RAG\n",
    "#\n",
    "# Requirements:\n",
    "#   pip install langchain langchain-huggingface chromadb\n",
    "\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "# Initialize local embedding model\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "# Create or connect to ChromaDB store (persistent directory will be used automatically)\n",
    "vectorstore = Chroma(\n",
    "    persist_directory=\"./datafiles/chroma_db_notes_full\",\n",
    "    embedding_function=embedding_model\n",
    ")\n",
    "\n",
    "# Extract clinical notes and metadata\n",
    "documents = df[\"note_text\"].tolist()\n",
    "metadata = df[[\"patient_num\", \"encounter_num\", \"start_date\"]].to_dict(orient=\"records\")\n",
    "\n",
    "# Add text + metadata to the Chroma vector store\n",
    "vectorstore.add_texts(texts=documents, metadatas=metadata)\n",
    "\n",
    "print(f\"Successfully embedded and stored {len(documents)} clinical notes using MiniLM and ChromaDB.\")\n"
   ],
   "id": "cb4d79a45a47b55e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Defining the Query for Clinical Note Retrieval",
   "id": "842f180969d8e94d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# -----------------------------------------------------------\n",
    "# 3. Define the Query for Clinical Note Retrieval\n",
    "# -----------------------------------------------------------\n",
    "# This cell defines a natural language query that will be used to search the embedded clinical notes stored in ChromaDB.\n",
    "\n",
    "# Key Concepts:\n",
    "# - The query should reflect a specific clinical information need.\n",
    "# - The vector store will compare the embedded form of this query to all stored clinical note vectors using semantic similarity.\n",
    "\n",
    "# Example Query:\n",
    "# \"Who has asthma and is taking Fluticasone and Albuterol?\"\n",
    "# This query aims to retrieve notes describing patients diagnosed with asthma who are also prescribed both Fluticasone and Albuterol.\n",
    "\n",
    "query = \"Who has asthma and is taking Fluticasone and Albuterol?\"\n",
    "\n",
    "print(query)\n"
   ],
   "id": "387fe73e7a1ed4d5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4. Retrieving Clinical Notes with Similarity and MMR Search\n",
    "\n",
    "This section demonstrates how to retrieve relevant clinical notes from ChromaDB using multiple vector-based search strategies. We compare traditional **similarity search** with more advanced techniques like **Maximal Marginal Relevance (MMR)**.\n",
    "\n",
    "### Key Retrieval Methods:\n",
    "\n",
    "1. **Similarity Search with Scores (Step 4.1)**\n",
    "   - Retrieves clinical notes ranked by semantic similarity to the input query.\n",
    "   - Returns relevance scores to support sorting and thresholding.\n",
    "\n",
    "2. **Score Threshold Filtering (Step 4.2)**\n",
    "   - Filters out low-confidence matches based on a minimum similarity score.\n",
    "   - Improves retrieval precision by returning only highly aligned documents.\n",
    "\n",
    "3. **Maximal Marginal Relevance (MMR) Search (Step 4.3)**\n",
    "   - Balances relevance and diversity in retrieved documents.\n",
    "   - Reduces redundancy while preserving contextual variety.\n",
    "\n",
    "### Why Use These Strategies?\n",
    "\n",
    "Effective retrieval is critical to building high-quality RAG pipelines. These techniques help:\n",
    "- Improve contextual relevance of the retrieved clinical notes\n",
    "- Eliminate noisy or marginal matches\n",
    "- Encourage diversity in content to support more robust, less biased LLM outputs\n",
    "\n",
    "<img src=\"./images/rag_retrieval.png\" alt=\"RAG Retrieval\" width=\"900\">\n"
   ],
   "id": "b43a3635d3cf133c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# -----------------------------------------------------------\n",
    "# 4.1. Performing Similarity Search with Relevance Scores\n",
    "# -----------------------------------------------------------\n",
    "# This cell retrieves clinical notes that are semantically similar to a given query.\n",
    "# Each returned result includes a relevance score that reflects how well the note\n",
    "# matches the query, enabling more transparent and controllable filtering.\n",
    "\n",
    "# Key Function:\n",
    "# - vectorstore.similarity_search_with_relevance_scores(query, k=10)\n",
    "#   Retrieves the top k most relevant documents with their similarity scores.\n",
    "\n",
    "# Use Case:\n",
    "# - This method is ideal for inspecting how well the embedding model is performing.\n",
    "# - It supports ranked retrieval and post-filtering for building RAG pipelines.\n",
    "\n",
    "# Score Interpretation (higher is more relevant):\n",
    "#   0.90 – 1.00 → Highly relevant\n",
    "#   0.70 – 0.90 → Strong relevance\n",
    "#   0.50 – 0.70 → Moderate relevance\n",
    "#   0.30 – 0.50 → Low relevance\n",
    "#   0.00 – 0.30 → Minimal or no relevance\n",
    "\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "results = vectorstore.similarity_search_with_relevance_scores(query, k=10)\n",
    "\n",
    "display(Markdown(\"### Retrieved Clinical Notes with Relevance Scores\"))\n",
    "\n",
    "for idx, (doc, score) in enumerate(results, 1):\n",
    "    patient = doc.metadata.get(\"patient_num\", \"N/A\")\n",
    "    encounter = doc.metadata.get(\"encounter_num\", \"N/A\")\n",
    "    date = doc.metadata.get(\"start_date\", \"N/A\")\n",
    "    doc_id = doc.id\n",
    "    excerpt = doc.page_content[:1000].replace(\"\\n\", \" \")\n",
    "\n",
    "    display(Markdown(\n",
    "        f\"**Document {idx}**  \\n\"\n",
    "        f\"- **Relevance Score:** `{score:.4f}`  \\n\"\n",
    "        f\"- **Patient Num:** `{patient}`  \\n\"\n",
    "        f\"- **Encounter Num:** `{encounter}`  \\n\"\n",
    "        f\"- **Start Date:** `{date}`  \\n\"\n",
    "        f\"- **Document ID:** `{doc_id}`  \\n\"\n",
    "        f\"- **Excerpt:**\\n\\n```text\\n{excerpt}...\\n```\"\n",
    "    ))\n",
    "\n",
    "\n"
   ],
   "id": "722f9bd17a7fe54e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# -----------------------------------------------------------\n",
    "# 4.2. Using a Retriever with a Score Threshold\n",
    "# -----------------------------------------------------------\n",
    "# This cell demonstrates how to configure a retriever that returns only documents\n",
    "# whose similarity scores exceed a defined threshold.\n",
    "\n",
    "# Key Parameters:\n",
    "# - search_type=\"similarity_score_threshold\":\n",
    "#     Instructs the retriever to filter results by a minimum score.\n",
    "# - search_kwargs={\"k\": 10, \"score_threshold\": 0.5}:\n",
    "#     - k: Number of top-ranked documents to consider.\n",
    "#     - score_threshold: Minimum relevance score required for inclusion.\n",
    "\n",
    "# Purpose:\n",
    "# This approach increases precision by filtering out low-quality matches.\n",
    "# It is especially useful in clinical settings where retrieval accuracy is essential.\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={\n",
    "        \"k\": 10,\n",
    "        \"score_threshold\": 0.6\n",
    "    }\n",
    ")\n",
    "\n",
    "results = retriever.invoke(query)\n",
    "\n",
    "display(Markdown(\"### Retrieved Clinical Notes (Score ≥ 0.6)\"))\n",
    "\n",
    "for idx, doc in enumerate(results, 1):\n",
    "    patient = doc.metadata.get(\"patient_num\", \"N/A\")\n",
    "    date = doc.metadata.get(\"start_date\", \"N/A\")\n",
    "    doc_id = doc.id\n",
    "    excerpt = doc.page_content[:1000].replace(\"\\n\", \" \")\n",
    "\n",
    "    display(Markdown(\n",
    "        f\"**Document {idx}**  \\n\"\n",
    "        f\"- **Patient Num:** `{patient}`  \\n\"\n",
    "        f\"- **Start Date:** `{date}`  \\n\"\n",
    "        f\"- **Document ID:** `{doc_id}`  \\n\"\n",
    "        f\"- **Excerpt:**\\n\\n```text\\n{excerpt}...\\n```\"\n",
    "    ))\n",
    "\n",
    "display(Markdown(f\"**Total relevant results:** {len(results)}\"))\n"
   ],
   "id": "f1aca9739171e3d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# -----------------------------------------------------------\n",
    "# 4.3. Performing Maximal Marginal Relevance (MMR) Search\n",
    "# -----------------------------------------------------------\n",
    "# This cell retrieves clinical notes using Maximal Marginal Relevance (MMR),\n",
    "# which balances relevance to the query and diversity across the results.\n",
    "\n",
    "# Key Parameters:\n",
    "# - max_marginal_relevance_search(): Retrieves results using MMR.\n",
    "# - fetch_k=100: Number of top documents considered before applying MMR.\n",
    "# - k=10: Final number of documents returned.\n",
    "# - lambda_mult:\n",
    "#     - 0.0 → maximize diversity\n",
    "#     - 1.0 → maximize relevance\n",
    "#     - 0.5 → balance between the two\n",
    "\n",
    "# Purpose:\n",
    "# MMR reduces redundancy while maintaining relevance, useful when diverse perspectives\n",
    "# on a clinical topic (e.g., treatment variations) are desired.\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "results = vectorstore.max_marginal_relevance_search(\n",
    "    query=query,\n",
    "    k=5,\n",
    "    fetch_k=500,\n",
    "    lambda_mult=0.5\n",
    ")\n",
    "\n",
    "display(Markdown(\"### Retrieved Clinical Notes Using MMR Search\"))\n",
    "\n",
    "for idx, doc in enumerate(results, 1):\n",
    "    patient = doc.metadata.get(\"patient_num\", \"N/A\")\n",
    "    date = doc.metadata.get(\"start_date\", \"N/A\")\n",
    "    doc_id = getattr(doc, \"id\", \"N/A\")\n",
    "    excerpt = doc.page_content[:1000].replace(\"\\n\", \" \")\n",
    "\n",
    "    display(Markdown(\n",
    "        f\"**Document {idx}**  \\n\"\n",
    "        f\"- **Patient Num:** `{patient}`  \\n\"\n",
    "        f\"- **Start Date:** `{date}`  \\n\"\n",
    "        f\"- **Document ID:** `{doc_id}`  \\n\"\n",
    "        f\"- **Excerpt:**\\n\\n```text\\n{excerpt}...\\n```\"\n",
    "    ))\n",
    "\n",
    "display(Markdown(f\"**Total results returned:** `{len(results)}`\"))\n"
   ],
   "id": "828479f4c3baa9bd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5. Generating Structured Responses with an LLM\n",
    "\n",
    "In this section, we take the clinical notes retrieved in the previous step and pass them into a Large Language Model (LLM) for analysis and summarization. This completes the RAG (Retrieval-Augmented Generation) workflow.\n",
    "\n",
    "### Key Steps:\n",
    "\n",
    "1. **Creating a Prompt Template for LLM Querying (Step 5.1)**\n",
    "   - Defines a reusable prompt structure to guide the LLM in analyzing and summarizing clinical notes.\n",
    "   - Ensures the output is consistent, structured, and clinically useful.\n",
    "\n",
    "2. **Invoking LLM model with Retrieved Context (Step 5.2)**\n",
    "   - Inserts the retrieved documents into the prompt.\n",
    "   - Sends the final prompt to an LLM (e.g., qwen2, qwen3, llama3) for generation.\n",
    "   - Outputs a structured answer to a medical query.\n",
    "\n",
    "### Purpose\n",
    "\n",
    "This final step showcases how LLMs can generate rich, relevant summaries or extractions from retrieved clinical data. It is particularly useful for clinical decision support, patient summarization, or intelligent search.\n",
    "\n",
    "<img src=\"./images/rag_generation.png\" alt=\"RAG Generation\" width=\"1250\">\n"
   ],
   "id": "60a469cbbda2e7de"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# -----------------------------------------------------------\n",
    "# 5.1. Create a Prompt Template for LLM Querying\n",
    "# -----------------------------------------------------------\n",
    "# This prompt template guides the LLM to generate structured, clinically relevant responses from retrieved clinical notes. The template is dynamic and reusable.\n",
    "\n",
    "# Context:\n",
    "# - Each clinical note is associated with metadata (patient_num, encounter_num, start_date).\n",
    "# - These identifiers help structure the output and ensure traceability.\n",
    "\n",
    "# Key Components:\n",
    "# - PromptTemplate.from_template(): Allows dynamic substitution of note content and query.\n",
    "# - {results}: Injects top-matching clinical notes as the context for the model.\n",
    "# - {query}: Represents the user's clinical question.\n",
    "# - Output format:\n",
    "#     - Patient Num, Gender, Age, Race\n",
    "#     - Visit Date\n",
    "#     - Summary of findings related to the query\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"You are a medical assistant analyzing clinical notes. \\n\\n\"\n",
    "\n",
    "    \"Answer the following question: {query}\\n\\n\"\n",
    "\n",
    "    \"Based on the following records: {retrieved_docs}\\n\\n\"\n",
    "\n",
    "    \"Provide your response using the following structure:\\n\"\n",
    "    \"- Patient Num: <patient_num>, Gender: <value>, Age: <value>, Race: <value>\\n\"\n",
    "    \"- Encounter: <encounter_num>, Visit Date: <start_date>\\n\"\n",
    "    \"- Summary: One paragraph summarizing the note and one paragraph answering the question.\\n\\n\"\n",
    "    \"- Has Asthma: <Yes/No>\"\n",
    "    \"Instructions:\\n\"\n",
    "    \"- Include all patients relevant to the query.\\n\"\n",
    "    \"- Use only the most recent note for each patient (identified by patient_num).\\n\"\n",
    ")\n"
   ],
   "id": "ebb9aec086115c34",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T18:23:51.702660Z",
     "start_time": "2025-05-14T18:21:47.087382Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -----------------------------------------------------------\n",
    "# 5.2. Use Retrieved Context to Invoke LLM and Generate Response\n",
    "# -----------------------------------------------------------\n",
    "# This step completes the RAG workflow by injecting the retrieved clinical notes\n",
    "# into a structured prompt and using an LLM (via Ollama) to generate a response.\n",
    "\n",
    "# Key Components:\n",
    "# - prompt_template.format(...): Fills in the template with clinical context and user query.\n",
    "# - model.invoke(...): Sends the completed prompt to the LLM for inference.\n",
    "# - display(Markdown(...)): Nicely renders the model's response in the notebook.\n",
    "\n",
    "from langchain_ollama import ChatOllama\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Initialize the local Ollama model (e.g., Qwen 2, LLaMA 3, etc.)\n",
    "model = ChatOllama(model=\"llama3:70b\")\n",
    "\n",
    "# Prepare the context text (combine page_content from results list)\n",
    "retrieved_context = \"\\n\\n---\\n\\n\".join([doc.page_content for doc in results])\n",
    "\n",
    "# Fill the prompt template with retrieved notes and the user's query\n",
    "final_prompt = prompt_template.format(\n",
    "    retrieved_docs=retrieved_context,\n",
    "    query=query\n",
    ")\n",
    "\n",
    "# Generate a structured response using the LLM\n",
    "response = model.invoke(final_prompt)\n",
    "\n",
    "# Display the LLM-generated output\n",
    "display(Markdown(\"### LLM-Generated Response\"))\n",
    "display(Markdown(response.content))\n"
   ],
   "id": "44506dfe18ccb7c6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "### LLM-Generated Response"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Here are the responses:\n\n**Patient 1**\n- Patient Num: 1000000005, Gender: Female, Age: 32, Race: Hispanic\n- Encounter: 477663, Visit Date: June 21, 2005\n- Summary: The patient presents with continued asthma symptoms despite regular usage of her asthma medications. She reports shortness of breath, wheezing, and a cough that disrupts her sleep.\n- Has Asthma: Yes\n\n**Patient 2**\n- Patient Num: 1000000088, Gender: Male, Age: 9, Race: Asian\n- Encounter: 477031, Visit Date: Oct 28, 2004\n- Summary: The patient presents with complications associated with his asthma, including wheezing and shortness of breath. He has an established history of asthma and allergic rhinitis.\n- Has Asthma: Yes\n\n**Patient 3**\n- Patient Num: 1000000112, Gender: Male, Age: 12, Race: Black\n- Encounter: 478135, Visit Date: December 5, 2005\n- Summary: The patient presents with poorly controlled asthma, evidenced by worsening symptoms and lung function test results. He reports frequent wheezing, episodes of dyspnea, and a persistent nocturnal cough.\n- Has Asthma: Yes\n\n**Patient 4**\n- Patient Num: 1000000089, Gender: Male, Age: 37, Race: Black\n- Encounter: 475021, Visit Date: September 9, 2002\n- Summary: The patient presents with manageable asthma under his current treatment regime. However, he reports occasional exacerbations during physical activity and pollen season.\n- Has Asthma: Yes\n\nNote that Patient 4 also has allergic rhinitis and joint pain, but the primary diagnosis is asthma.\n\nOnly one patient (Patient 3) has a medication regimen that includes Atrovent (ipratropium bromide), Flovent (fluticasone), Prednisolone, Zantac, and Zithromax."
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "4d0b771d6e91fd4e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
