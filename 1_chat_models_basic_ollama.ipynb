{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "![i2b2 Logo](images/transmart-logo.png)\n",
    "\n",
    "\n",
    "# Using LLM for Clinical Note Analysis (Zero-shot)\n",
    "This Notebook demonstrates how to use Azure-hosted OpenAI models with LangChain. The notebook follows a step-by-step approach to set up authentication, initialize the model, create structured prompts, and generate responses. The key components covered include:#\n",
    "\n",
    "- ## REVIEW !!! \n",
    "- Loading environment variables\n",
    "- Setting up Azure authentication\n",
    "- Creating and formatting chat prompts\n",
    "- Invoking the OpenAI model\n",
    "- Displaying the AI-generated response\n",
    "\n",
    "Each cell in the notebook builds upon the previous one to progressively set up and execute an AI-driven conversation."
   ],
   "id": "a2b994958c92d3b8"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-01T15:54:47.707466Z",
     "start_time": "2025-05-01T15:54:47.129377Z"
    }
   },
   "source": [
    "# -----------------------------------------------------------\n",
    "# 1. Ollama Installation & Model Download\n",
    "# -----------------------------------------------------------\n",
    "# üìå One-time setup instructions for workshop participants\n",
    "\n",
    "# ‚öôÔ∏è Step 1: Install Ollama\n",
    "#   - Download from: https://ollama.com/download\n",
    "#   - Follow your OS-specific install steps\n",
    "#   - Restart your terminal after installation\n",
    "#   - Verify install: run `ollama version` in terminal\n",
    "\n",
    "# ‚öôÔ∏è Step 2: Automatically pull the required model\n",
    "#   - You can change the model name below if needed (e.g., \"qwen3\")\n",
    "\n",
    "import subprocess\n",
    "\n",
    "# Choose your model\n",
    "model_name = \"qwen2:7b\"  # Change to \"qwen3\" if preferred\n",
    "\n",
    "# Pull the model (safe to run multiple times)\n",
    "print(f\"üì• Downloading model '{model_name}' via Ollama...\")\n",
    "subprocess.run([\"ollama\", \"pull\", model_name], check=True)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Downloading model 'qwen2:7b' via Ollama...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[?2026h\u001B[?25l\u001B[1Gpulling manifest ‚†ã \u001B[K\u001B[?25h\u001B[?2026l\u001B[?2026h\u001B[?25l\u001B[1Gpulling manifest ‚†ô \u001B[K\u001B[?25h\u001B[?2026l\u001B[?2026h\u001B[?25l\u001B[1Gpulling manifest ‚†π \u001B[K\u001B[?25h\u001B[?2026l\u001B[?2026h\u001B[?25l\u001B[1Gpulling manifest ‚†∏ \u001B[K\u001B[?25h\u001B[?2026l\u001B[?2026h\u001B[?25l\u001B[1Gpulling manifest ‚†º \u001B[K\u001B[?25h\u001B[?2026l\u001B[?2026h\u001B[?25l\u001B[1Gpulling manifest \u001B[K\n",
      "pulling 43f7a214e532: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè 4.4 GB                         \u001B[K\n",
      "pulling 77c91b422cc9: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè 1.4 KB                         \u001B[K\n",
      "pulling c156170b718e: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  11 KB                         \u001B[K\n",
      "pulling f02dd72bb242: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   59 B                         \u001B[K\n",
      "pulling 75357d685f23: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   28 B                         \u001B[K\n",
      "pulling 648f809ced2b: 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  485 B                         \u001B[K\n",
      "verifying sha256 digest \u001B[K\n",
      "writing manifest \u001B[K\n",
      "success \u001B[K\u001B[?25h\u001B[?2026l\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['ollama', 'pull', 'qwen2:7b'], returncode=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T15:54:55.189117Z",
     "start_time": "2025-05-01T15:54:55.185656Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -----------------------------------------------------------\n",
    "# 2. Initialize the Qwen Model via Ollama\n",
    "# -----------------------------------------------------------\n",
    "# Sets up the model interface using LangChain's Ollama wrapper\n",
    "\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "# Use the same model name as in the previous cell\n",
    "model = ChatOllama(model=model_name)\n",
    "\n",
    "print(f\"\\n‚úÖ Ollama Model '{model_name}' is loaded and ready to use.\")\n"
   ],
   "id": "573f3b466e03f7c1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Ollama Model 'qwen2:7b' is loaded and ready to use.\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. Basic Prompt Interaction\n",
    "<img src=\"https://github.com/v-mourajr/mongan_llm_workshop/blob/master/images/basic_prompt.png?raw=true\" alt=\"Basic Prompt\" width=\"800\">"
   ],
   "id": "a8a750da658a7524"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T15:56:52.977142Z",
     "start_time": "2025-05-01T15:55:04.920270Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -----------------------------------------------------------\n",
    "# 3. Basic Prompt Interaction\n",
    "# -----------------------------------------------------------\n",
    "# This cell shows how to send structured messages (system + user prompt)\n",
    "# to the Qwen model using LangChain's Ollama integration.\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# Define the system and user messages\n",
    "messages = [\n",
    "    SystemMessage(content=(\n",
    "        \"You are a knowledgeable medical provider with expertise in diagnosing and managing various diseases. \"\n",
    "        \"Provide clear, evidence-based, and patient-friendly explanations about medical conditions, symptoms, and treatments.\"\n",
    "    )),\n",
    "    HumanMessage(content=\"What is asthma? What are its common symptoms and treatments?\")\n",
    "]\n",
    "\n",
    "# Send the messages to the model and get the response\n",
    "response = model.invoke(messages)\n",
    "\n",
    "# Display the model's reply\n",
    "print(\"üß† Model Response:\\n\")\n",
    "print(response.content)\n"
   ],
   "id": "c84f9839d5749e5a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Model Response:\n",
      "\n",
      "**Asthma**\n",
      "\n",
      "**Definition**: Asthma is a chronic inflammatory condition of the airways in your lungs. It causes recurring episodes of breathlessness, wheezing, chest tightness, or coughing. The inflammation leads to narrowing of the bronchial tubes (the airways), making it difficult for air to flow in and out of the lungs.\n",
      "\n",
      "**Common Symptoms**: Asthma symptoms can vary widely between individuals and even from one episode to another within a person. Common symptoms include:\n",
      "\n",
      "1. **Wheezing**: A whistling sound when breathing, heard most often during exhalation.\n",
      "2. **Coughing**\n",
      "3. **Shortness of breath (dyspnea)**\n",
      "4. **Chronic or episodic chest tightness**\n",
      "5. **Recurring nocturnal symptoms** (waking up due to difficulty in breathing)\n",
      "\n",
      "These symptoms are typically triggered by irritants such as allergens, air pollution, exercise, cold temperatures, viral infections, and certain medications.\n",
      "\n",
      "**Diagnosis**: Asthma is usually diagnosed based on the history of symptoms, physical examination, and a pulmonary function test. The latter can measure how well your lungs are working and help determine if asthma is present.\n",
      "\n",
      "**Treatments**:\n",
      "\n",
      "1. **Medications to Control Asthma**:\n",
      "   - **Inhaled Corticosteroids**: These are typically used daily to reduce airway inflammation.\n",
      "   - **Long-acting Beta Agonists (LABAs)**: Often used in combination with corticosteroids, these help keep the bronchial tubes relaxed and open.\n",
      "\n",
      "2. **Quick Relief or Rescue Medications**:\n",
      "   - **Short-Acting Beta Agonists (SABAs)** like albuterol: Used during an asthma attack to quickly relieve symptoms by relaxing muscles around the airways.\n",
      "   - **Methacholine Challenge**: This test can help confirm that a patient is experiencing bronchial hyperresponsiveness, which is one of the key features of asthma.\n",
      "\n",
      "3. **Avoidance Measures**:\n",
      "   - Identifying and avoiding triggers is crucial in managing asthma. Common triggers include pollen, dust mites, pet dander, mold spores, strong odors from household chemicals, or smoke.\n",
      "   \n",
      "4. **Long-term Management Plan**: This includes an action plan that helps manage daily symptoms and occasional flare-ups to prevent severe attacks.\n",
      "\n",
      "5. **Ongoing Monitoring**:\n",
      "   - Regular check-ups with a healthcare provider can help adjust medications as needed based on how well the person is managing their asthma over time.\n",
      "\n",
      "6. **Education and Support**: Learning about asthma management, practicing good self-care, using a peak flow meter (to monitor lung function), joining support groups, or seeking psychological counseling if asthma is affecting quality of life significantly.\n",
      "\n",
      "**Preventive Measures**: Avoiding triggers, maintaining indoor air quality by using air filters, keeping pets out of the bedroom, and keeping humidity levels in check can also help prevent asthma attacks. \n",
      "\n",
      "It's important to consult with a healthcare provider for personalized management strategies based on individual needs and circumstances.\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4. Using ChatPromptTemplate for Dynamic Queries\n",
    "<img src=\"https://github.com/v-mourajr/mongan_llm_workshop/blob/master/images/prompt_template.png?raw=true\" alt=\"Basic Prompt\" width=\"800\">\n"
   ],
   "id": "70e18716ffd84a04"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# -----------------------------------------------------------\n",
    "# 4. Using ChatPromptTemplate for Dynamic Queries\n",
    "# -----------------------------------------------------------\n",
    "# Demonstrates how to create a reusable prompt template with dynamic input variables using LangChain.\n",
    "\n",
    "# Key Components:\n",
    "#   - ChatPromptTemplate: Allows dynamic variables in prompts, making interactions more flexible.\n",
    "#   - SystemMessage: Sets the AI‚Äôs role as a medical provider, ensuring responses are clear and evidence-based.\n",
    "#   - HumanMessage: Contains a query template with a placeholder ({disease}), allowing different medical conditions to be queried dynamically.\n",
    "#   - prompt_template.invoke({\"disease\": disease}): Fills in the variable \"disease\" with the specified condition (e.g., \"epilepsy\").\n",
    "#   - model.invoke(prompt): Sends the formatted query to the AI model for a response.\n",
    "\n",
    "# Purpose:\n",
    "# This approach enables reusable prompts where users can query different diseases without modifying the prompt structure.\n",
    "# It improves scalability and efficiency for medical applications or chatbots handling multiple medical conditions.\n",
    "\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "ai_role = \"5 year-old\"\n",
    "disease = \"epilepsy\"\n",
    "\n",
    "# messages = [\n",
    "#     (\"system\", f\"You are a knowledgeable {ai_role}. Provide clear, evidence-based, and patient-friendly explanations about medical conditions, symptoms, and treatments.\"),\n",
    "# \n",
    "#     (\"human\", \"What is {disease}? What are its common symptoms and treatments?\"),\n",
    "# ]\n",
    "\n",
    "messages = [\n",
    "    (\"system\", f\"You are a knowledgeable medical provider. Provide clear and patient-friendly explanations about medical conditions, symptoms, and treatments, ensuring they are suitable for a {ai_role}.\"),\n",
    "\n",
    "    (\"human\", \"What is {disease}? What are its common symptoms and treatments?\"),\n",
    "]\n",
    "\n",
    "# Create PromptTemplate\n",
    "prompt_template = ChatPromptTemplate.from_messages(messages)\n",
    "\n",
    "# Plug-in user variables\n",
    "prompt = prompt_template.invoke({\"ai_role\": ai_role , \"disease\": disease})\n",
    "\n",
    "# invoke model\n",
    "result = model.invoke(prompt)\n",
    "print(result.content)"
   ],
   "id": "ff4be7952c8bc9f9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# -----------------------------------------------------------\n",
    "# 5. Using ChatPromptTemplate for Clinical Note Analysis\n",
    "# -----------------------------------------------------------\n",
    "# Demonstrates how to create a structured prompt template for extracting medical details from clinical notes.\n",
    "\n",
    "# Key Components:\n",
    "#   - ChatPromptTemplate: Creates a reusable prompt structure for analyzing clinical notes.\n",
    "#   - SystemMessage: Defines the AI‚Äôs role as a medical documentation assistant, ensuring accurate extraction of medical details.\n",
    "#   - HumanMessage: Contains a structured query with a placeholder ({patient_note}), allowing different clinical notes to be analyzed dynamically.\n",
    "#   - prompt_template_notes.invoke({\"patient_note\": note_text}): Fills in the variable \"patient_note\" with the actual clinical note text.\n",
    "#   - model.invoke(prompt): Sends the formatted query to the AI model for processing.\n",
    "\n",
    "# Purpose:\n",
    "# This approach enables automated medical text processing, ensuring structured extraction of relevant information such as demographics, chief complaints, medications, and asthma status.\n",
    "# It improves efficiency in clinical documentation and can be integrated into medical record systems for automated analysis.\n",
    "\n",
    "\n",
    "messages_notes = [\n",
    "    (\n",
    "        \"system\", \n",
    "        \"You are an advanced medical documentation assistant with expertise in clinical text analysis. Your task is to review a given clinical note and extract relevant medical details accurately.\"\n",
    "    ),\n",
    "    \n",
    "    (\n",
    "        \"human\", \n",
    "        \"Please analyze the following clinical note: {patient_note}. \\n\\n\"\n",
    "        \"Extract and list the following information:\\n\"\n",
    "        \"1. Patient demographics\\n\"\n",
    "        \"2. Chief Complaints\\n\"\n",
    "        \"3. Current Medications\\n\"\n",
    "        \"4. Determine whether the patient has asthma (Yes/No), based on explicit mentions or related diagnoses.\\n\\n\"\n",
    "        \"Provide the output in a structured format.\"\n",
    "    )\n",
    "]\n",
    "\n",
    "prompt_template_notes = ChatPromptTemplate.from_messages(messages_notes)\n"
   ],
   "id": "2f958c9284e3da1f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# -----------------------------------------------------------\n",
    "# 6. Loading and Reading a Patient Note\n",
    "# -----------------------------------------------------------\n",
    "# Demonstrates how to load a clinical note from a file for further processing.\n",
    "\n",
    "# Key Components:\n",
    "#   - input_dir: Specifies the directory where patient notes are stored.\n",
    "#   - filename: Defines the specific file to be loaded, containing a patient's medical note.\n",
    "#   - os.path.join(input_dir, filename): Constructs the full file path dynamically.\n",
    "#   - open(file_path, \"r\"): Opens the file in read mode and loads the content into the variable \"patient_note\".\n",
    "#   - print(f\"\\nPatient Note:\\n\\n{patient_note}\"): Displays the loaded note for verification.\n",
    "\n",
    "# Purpose:\n",
    "# This step ensures that patient notes are correctly loaded before being analyzed by the AI model.\n",
    "# It enables seamless integration with document processing pipelines for clinical text analysis.\n",
    "\n",
    "\n",
    "input_dir = 'data_prep/patient_notes_old'\n",
    "filename = 'note_1000000064_20090608.txt' \n",
    "\n",
    "# examples without Asthma: \n",
    "# -----------------------------------------------------------\n",
    "# 1000000002, 1000000003, 1000000009, 1000000010, 1000000013, \n",
    "# 1000000023, 1000000036, 1000000040, 1000000047, 1000000048, \n",
    "# 1000000052, 1000000063, 1000000064, 1000000068, 1000000071, \n",
    "# 1000000082, 1000000086, 1000000087, 1000000093, 1000000101, \n",
    "# 1000000103, 1000000107\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "\n",
    "# Load the note txt\n",
    "file_path = os.path.join(input_dir, filename)\n",
    "with open(file_path, \"r\") as file:\n",
    "    patient_note = file.read()\n",
    "    \n",
    "print(f\"\\nPatient Note:\\n\\n{patient_note}\")"
   ],
   "id": "ed77019c319ec4f7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# -----------------------------------------------------------\n",
    "# 7. Invoking the AI Model for Clinical Note Analysis\n",
    "# -----------------------------------------------------------\n",
    "# Demonstrates how to process a patient note using a structured prompt and invoke the AI model for analysis.\n",
    "\n",
    "# Key Components:\n",
    "#   - prompt_template_notes.invoke({\"patient_note\": patient_note}): \n",
    "#     Dynamically fills the prompt template with the actual clinical note text.\n",
    "#   - model.invoke(prompt_notes): \n",
    "#     Sends the formatted query to the AI model for processing.\n",
    "#   - print(result_note.content): \n",
    "#     Displays the AI-generated structured output containing extracted medical details.\n",
    "\n",
    "# Purpose:\n",
    "# This approach enables automated extraction of structured medical information from clinical notes.\n",
    "# It ensures efficient and standardized processing of patient datafiles, aiding in medical documentation and decision-making.\n",
    "\n",
    "prompt_notes = prompt_template_notes.invoke({\"patient_note\": patient_note})\n",
    "\n",
    "# invoke model\n",
    "result_note = model.invoke(prompt_notes)\n",
    "print(result_note.content)\n"
   ],
   "id": "43a71ee0339c8ac2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "332511529a8a3505",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
